\documentclass[letter,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{float}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{color}
\usepackage{tabularx}
\begin{document}

\section{Datasets}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Fig/datasetLengthDistributions.png}
    \caption{Distributions of sequence lengths for targets in training set (blue) and test set (red).}
    \label{Fig:dataLengthDist}
\end{figure}

\begin{table}[H]
\begin{center}
\begin{tabular}{ c | c | l }
    
    Test set ID & Closest training set ID & E-value \\
    \hline
    T0768 & T0690 & $2.70\times 10^{-13}$ \\
    T0770 & T0645 & $1.79\times 10^{-13}$ \\
    T0772 & T0518 & $1.89\times 10^{-7}$ \\
    T0776 & T0707 & $3.98\times 10^{-5}$ \\
    T0783 & T0699 & $1.19\times 10^{-22}$ \\
    T0798 & T0308 & $9.57\times 10^{-6}$ \\
    T0813 & T0398 & $2.45\times 10^{-5}$ \\
    T0819 & T0636 & $8.66\times 10^{-15}$ \\
    T0854 & T0324 & $2.13\times 10^{-13}$ \\
\end{tabular}
%   
    \caption{Closest homolog sequences from the training set. A
    sequence pair is reported if at least one training sequence aligns
    to a test sequence with a blastp E-value less than $10^{-4}$. Only
    the top alignment is reported for each test sequence.}
%
\label{Tbl:datasetsSimilarity}
\end{center}
\end{table}


\begin{table}[H]
\begin{center}
\begin{tabular}{ l | l | l }

    Common family & Test set target & Train set targets \\
    \hline
    %%% I've removed the version numbers of the Pfam IDs
    %%% I don't think we need them
    PF00795 & T0794 & T0542 \\ \hline
    PF13472 & T0776 & T0448, T0297, T0286, T0750 \\ \hline
    PF03807 & T0813 & T0398, T0393, T0702 \\ \hline
    PF00266 & T0801 & T0339, T0697 \\ \hline
    PF01128 & T0783 & T0699, T0420 \\ \hline
    PF07949 & T0780 & T0572 \\ \hline
    PF13577 & T0815 & T0752, T0736 \\ \hline
    PF12804 & T0783 & T0593, T0699, T0420 \\ \hline
    PF13242 & T0854 & T0371, T0341, T0303, T0324, T0330, T0329, T0418 \\ \hline
    PF13306 & T0768 & T0690, T0671, T0713, T0653 \\ \hline
    PF12741 & T0770 & T0664, T0645, T0532 \\ \hline
    PF00025 & T0798 & T0308 \\ \hline
    PF12872 & T0792 & T0549 \\ \hline
    PF03446 & T0813, T0851 & T0398, T0393, T0702 \\ \hline
    PF00155 & T0801, T0819 & T0591, T0636, T0436, T0697 \\ \hline
    PF13419 & T0854 & T0371, T0341, T0303, T0379, T0324, T0330, T0329, T0418, T0635 \\ \hline
    PF12680 & T0815 & T0451, T0475 \\ \hline
    PF06439 & T0772 & T0518 \\ \hline
    PF12771 & T0770 & T0664, T0645, T0532 \\ \hline
    PF08477 & T0798 & T0308 \\ \hline
    PF00657 & T0776 & T0297, T0286, T0679 \\ \hline
    PF00071 & T0798 & T0308 \\ \hline
    PF00702 & T0854 & T0303, T0324, T0330, T0329, T0418, T0635 \\ \hline
    PF01926 & T0798 & T0308 \\ \hline
    PF12697 & T0764 & T0672 \\ \hline
\end{tabular}
   
\caption{Targets from test and training sets that belong to the same Pfam
family \cite{finn2016pfam}, based on a HMMER search \cite{finn2015hmmer} with an
E-value cutoff of 1.0. With that cutoff, 403 of the 564 training
targets and 65 of the 83 test targets could be assigned
families. There are 25 families containing at least one test sequence
and one training sequence, involving a total of 16 test targets and 42
training targets. Each of the 25 families belongs to a distinct Pfam
clan.}
%
\label{Tbl:SharedPfam}
\end{center}
\end{table}


Figure \ref{Fig:foldsGraph} shows the classification of the test set
into ECOD groups. Branches drawn in black correspond to groups
containing structures from the training set as well. Branches drawn in
grey correspond to groups unique to the test set. Targets T0773,
T0797, and T0816 are excluded from the analysis because they have no
ECOD classification, and targets T0820, T0823, T0824, T0827, T0835,
and T0836 are excluded because they have no structure in the RCSB PDB.

Four architecture groups present overlap at all levels between the
training and test sets: ``a/b barrels'', ``beta duplicates or obligate
multimers'', ``a+b complex topology'', and ``a+b four layers''.
%%% Is this a useful observation? I don't know what to do with that
%%% information. More generally, I really don't know what to make of
%%% Figure 2. It shows a lot of information that we don't need and the
%%% information we need is mainly in Figure 3.


\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Fig/folds_graph.png}
%
    \caption{Classification of the test set structures into the lower
    four ECOD structural levels (from the center out): architecture
    (A), possible homology (X), homology (H), and topology (T). The
    names of the architecture types are shown in the outer circle of
    the diagram.
%%% Why do you have two different architecture names in the same A
%%% group? (brown color: ``alpha complex topology'' and ``alpha
%%% arrays'')
    The grey lines denote test set classes that have no
    respective representative in the training set. The black lines
    show the classes that have representatives in both training and
    test sets. We do not show the F-groups because they have litle
    overlap among the training and test sets.
%%% Why not showing the F-groups?
}
%
    \label{Fig:foldsGraph}
\end{figure}

\section{Model}

\begin{table}[H]
\begin{center}
\makebox[0pt][c]{
\hskip-\footskip
\begin{tabularx}{0.8\paperwidth}{ l | l | c | c | c }

    Number & Layer name & Input dimentions & Output dimensions & Parameters \\
    \hline
    1&3D Convolution & $11\times 120\times 120\times 120$ & $16\times 118\times 118\times 118$ & 
                    Filter size: $3\times 3\times 3$ Stride: $1\times 1\times 1$\\
    2&ReLU & & & \\
    3&Max pooling & $16\times 118\times 118\times 118$ & $16\times 58\times 58\times 58$ & 
                    Filter size: $3\times 3\times 3$ Stride: $2\times 2\times 2$ \\
    \hline 
    4&3D Convolution & $16\times 58\times 58\times 58$ & $32\times 56\times 56\times 56$ & 
                    Filter size: $3\times 3\times 3$ Stride: $1\times 1\times 1$\\
    5&Batch normalization & & & \\
    6&ReLU & & & \\
    7&Max pooling & $32\times 56\times 56\times 56$ & $32\times 27\times 27\times 27$ & 
                    Filter size: $3\times 3\times 3$ Stride: $2\times 2\times 2$ \\
    \hline
    8&3D Convolution & $32\times 27\times 27\times 27$ & $32\times 25\times 25\times 25$ & 
                    Filter size: $3\times 3\times 3$ Stride: $1\times 1\times 1$\\
    9&Batch normalization & & & \\
    10&ReLU & & & \\
    11&3D Convolution & $32\times 25\times 25\times 25$ & $64\times 23\times 23\times 23$ & 
                    Filter size: $3\times 3\times 3$ Stride: $1\times 1\times 1$\\
    12&Batch normalization & & & \\
    13&ReLU & & & \\
    14&Max pooling & $64\times 23\times 23\times 23$ & $64\times 11\times 11\times 11$ & 
                    Filter size: $3\times 3\times 3$ Stride: $2\times 2\times 2$ \\
    \hline
    15&3D Convolution & $64\times 11\times 11\times 11$ & $128\times 9\times 9\times 9$ & 
                    Filter size: $3\times 3\times 3$ Stride: $1\times 1\times 1$\\
    16&Batch normalization & & & \\
    17&ReLU & & & \\
    18&3D Convolution & $128\times 9\times 9\times 9$ & $128\times 7\times 7\times 7$ & 
                    Filter size: $3\times 3\times 3$ Stride: $1\times 1\times 1$\\
    19&Batch normalization & & & \\
    20&ReLU & & & \\
    21&3D Convolution & $128\times 7\times 7\times 7$ & $256\times 5\times 5\times 5$ & 
                    Filter size: $3\times 3\times 3$ Stride: $1\times 1\times 1$\\
    22&Batch normalization & & & \\
    23&ReLU & & & \\
    24&3D Convolution & $256\times 5\times 5\times 5$ & $512\times 3\times 3\times 3$ & 
                    Filter size: $3\times 3\times 3$ Stride: $1\times 1\times 1$\\
    25&Batch normalization & & & \\
    26&ReLU & & & \\
    27&Max pooling & $512\times 3\times 3\times 3$ & $512\times 1\times 1\times 1$ & 
                    Filter size: $3\times 3\times 3$ Stride: $2\times 2\times 2$ \\
    \hline
    28&Reshape & $512\times 1\times 1\times 1$ & $512$ & \\
    \hline
    29&Linear & 512 & 256 & \\
    30&ReLU & & & \\
    31&Linear & 256 & 128 & \\
    32&ReLU & & & \\
    33&Linear & 128 & 1 & \\
    \hline

\end{tabularx}
\hskip\headheight
}
\caption{More details of the model architecture.}
\label{Tbl:SuppModel}
\end{center}
\end{table}

\section{Training}
\begin{table}[H]
\begin{center}
\begin{tabular}{ l | l }

    Parameter & Value \\
    \hline
    Learning rate& 0.0003\\
    Learning rate decay& 0.01\\
    GDT\_TS threshold& 0.01\\
    Algorithm& Adam
    
\end{tabular}
\caption{Non-default training parameters}
%
\label{Tbl:TrainingParam}
\end{center}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Fig/epoch40_funnels.png}
    \caption{Scoring funnels on the validation set at epoch 40. The score was sampled once using random rotation and translation.}
    \label{Fig:ValidationEpoch40}
\end{figure}

\section{Results}
\begin{figure}[H]
    \centering
    \makebox[0pt][c]{
    \hskip-\footskip
    \includegraphics[width=\paperwidth]{Fig/CASP11Stage1_SCWRL_sFinal_funnels.png}
    \hskip\headheight
    }
    \caption{Scoring funnels on Stage1 CASP11}
    \label{Fig:Satage1CASP11Funnels}
\end{figure}

\begin{figure}[H]
    \centering
    \makebox[0pt][c]{
    \hskip-\footskip
    \includegraphics[width=\paperwidth]{Fig/CASP11Stage2_SCWRL_sFinal_funnels.png}
    \hskip\headheight
    }
    \caption{Scoring funnels on Stage2 CASP11}
    \label{Fig:Satage2CASP11Funnels}
\end{figure}

\section{Analysis}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Fig/CASP11Stage1_SCWRL_activations_pca.png}
    \caption{First three principal components of layer 28 activations versus model score (color bar).}
    \label{Fig:PCA}
\end{figure}



\bibliography{citations.bib}{}
\bibliographystyle{plain}

\end{document}